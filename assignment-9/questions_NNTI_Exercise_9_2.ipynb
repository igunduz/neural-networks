{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f3e234d",
   "metadata": {},
   "source": [
    "Name:   \n",
    "Matrikelnummer:  \n",
    "Email:   \n",
    "   \n",
    "Name:   \n",
    "Matrikelnummer:   \n",
    "Email:\n",
    "\n",
    "Name:    \n",
    "Matrikelnummer:    \n",
    "Email:    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada51e96",
   "metadata": {},
   "source": [
    "#### Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb034177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import necessary libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121bd9f9",
   "metadata": {},
   "source": [
    "# 9.2 Design your CNN (4 points\n",
    "\n",
    "Please create a ```solution.py``` file where you define the following:\n",
    "\n",
    "\n",
    "1. A ```function``` where you use pytorch's Dataset and Dataloader class, and it should return you the desired split for the dataset. The function should have ```split``` as one of its argument and the call to Dataset class should respect this argument. The desired role of function is as follows:\n",
    "    - Load the ```SVHN``` dataset using the built-in PyTorch datasets and data loaders.\n",
    "    - Preprocess the data as needed, such as by resizing, cropping, and normalizing the images.\n",
    "    - Returns the Dataloader object for specified split\n",
    "    - **(Optional)** Try incorporating different transform based on whether it's **train / test / extra** ```split``` of dataset you are using. You are free to scour internet for this, but be sure to cite if you end up using someone else's code. You should also be able to explain **why** using different transform functions could be useful and what advantage your particular implementation has.\n",
    "    \n",
    "2. A ```class``` for your implementation of CNN which does the following:\n",
    "    - Define the CNN model architecture, including the choice of layers, kernel size, and number of filters.\n",
    "    - **(Optional)** treat number of layers, kernel size, filters, padding etc as arguments when you are defining your class. This would help you create different networks without having the need to edit ```solution.py``` file.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1f9876-0e5b-496d-9f8d-ce3366e0334f",
   "metadata": {},
   "source": [
    "### Train your model(s) by importing your implementation from ```solution.py``` file in this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f66f378",
   "metadata": {},
   "source": [
    "- Define a loss function and optimizer for training the model.\n",
    "- Train the model on the training data and evaluate its performance on the validation data.\n",
    "- Adjust the hyper-parameters and model architecture as needed to improve performance.\n",
    "- Test the different models on the test data and report the results. Do you see a relation of hyper-parameter tuning w.r.t. your design choices for the network?\n",
    "- **Optionally** Briefly explain your observations from the last point. You may also want to consider evaluating the model on additional benchmarks or real-world tasks to demonstrate its performance in different settings to present during tutorials. You will receive an **additional bonus** point for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ffe95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run your experiments and plot the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a0a988-4d98-45b3-9529-19f59e96daf1",
   "metadata": {},
   "source": [
    "## BONUS (1.5 + 1.5 points)\n",
    "- Recall the custom Dataset and DataLoaders exercise from the first assignment? Create a custom data-loading pipeline (i.e. Dataset and Dataloader) to be used with your model. Implement the transform functionality as collate_fn. (0.5 + 1)\n",
    "- Consider using a pre-trained model as a starting point and fine-tuning it on the SVHN dataset. Briefly contrast the performance with your design choices to justify the gain or loss in performance.\n",
    "\n",
    "Here are some tutorials for finetuning pre-trained models: https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html & https://huggingface.co/docs/transformers/training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bd9b92-b41b-4305-ae27-50b39ca2f739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus TODO:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
