{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "800a5a92",
   "metadata": {},
   "source": [
    "## Team Members\n",
    "\n",
    "Deborah Dormah Kanubala, dkanubala@aimsammi.org, 7025906:   \n",
    "Irem Begüm Gündüz, irgu00001@stud.uni-saarland.de, 7026821:  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c58443",
   "metadata": {},
   "source": [
    "## Exercise 2.3 PCA for visualization purposes (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcffbd9",
   "metadata": {},
   "source": [
    "In this exercise you will perform visualization of [MNIST](http://yann.lecun.com/exdb/mnist/) dataset using PCA. The end result of this exercise should look like [Embedding Projector](https://projector.tensorflow.org/) (please select \"Mnist with images\" in the dropdown menu on the left of the page).  \n",
    "Write your code in the respective cells. Of course, you can add additional cells or change their order, but please don't significantly change the structure of the notebook. You must use PyTorch tensors to perform all the calculations.  \n",
    "For each question that requires written answer, please write it in a markdown cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68bb486e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torch import dot\n",
    "import torchvision\n",
    "import numpy as np\n",
    "#from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0e9f12",
   "metadata": {},
   "source": [
    "#### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7772d6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000, 784])\n"
     ]
    }
   ],
   "source": [
    "# Download the dataset and save it to a local folder. You should use the train set.\n",
    "mnist_dataset = torchvision.datasets.MNIST('data/', train=True, download=True)\n",
    "\n",
    "X, Y = mnist_dataset.data, mnist_dataset.targets\n",
    "print(X.shape)\n",
    "\n",
    "X_flat = X.reshape(-1, 28*28).float()\n",
    "print(X_flat.shape)\n",
    "\n",
    "# We must make the data zero-centered before applying PCA\n",
    "M = torch.mean(X_flat)\n",
    "X_flat = X_flat - M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db45fa01",
   "metadata": {},
   "source": [
    "### 2.2.1. Perform PCA on the input data (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3ab4bc",
   "metadata": {},
   "source": [
    "Calculate covariance matrix of the input data. Hint: You can use torch.matmul for matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00535541",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_matrix = torch.cov(X_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e7ca0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the covarience matrix:  tensor([[6352.0454, 3070.6653,  471.4934,  ..., 3180.9722, 1501.1931,\n",
      "         1407.6777],\n",
      "        [3070.6653, 7046.0498,  420.2851,  ..., 1644.9565, 3016.0024,\n",
      "         2129.1047],\n",
      "        [ 471.4934,  420.2851, 4306.1914,  ...,  497.0110,  283.5911,\n",
      "          683.9412],\n",
      "        ...,\n",
      "        [3180.9722, 1644.9565,  497.0110,  ..., 5118.6855, 1147.0188,\n",
      "         1496.3334],\n",
      "        [1501.1931, 3016.0024,  283.5911,  ..., 1147.0188, 4416.5674,\n",
      "         1072.9625],\n",
      "        [1407.6777, 2129.1047,  683.9412,  ..., 1496.3334, 1072.9625,\n",
      "         4571.1670]])\n"
     ]
    }
   ],
   "source": [
    "print(\"This is the covarience matrix: \", cov_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf63221",
   "metadata": {},
   "source": [
    "Perform eigendecomposion of the covariance matrix. Hint: you can use torch.linalg.eig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b86333",
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_vals, eig_vecs = torch.linalg.eigh(cov_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513a337a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Eigenvectors \\n%s' %eig_vecs)\n",
    "print('\\nEigenvalues \\n%s' %eig_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9355491",
   "metadata": {},
   "source": [
    "### 2.2.2 Analyzing the results of PCA (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb5fdd8",
   "metadata": {},
   "source": [
    "Extract the first two principal components of the data, i.e. reduce the dimensionality of the dataset to 2. Plot the result. Different numbers must be represented as different colors on the scatter plot. You can use a randomly sampled portion of the data so that the plot doesn't get cluttered.   \n",
    "Describe whether it's possible to differentiate the numbers in 2 dimensions. Are there any additional observations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4507b128",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a list from evecs and evals and sort the list from high to low\n",
    "epairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))].sort(key=lambda x: x[0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf65fd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the first two evec\n",
    "W = np.hstack((epairs[0][1].reshape(4,1), epairs[1][1].reshape(4,1)))\n",
    "\n",
    "#Project data into new space\n",
    "Y = X_flat.dot(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d264a8ac",
   "metadata": {},
   "source": [
    "No, it's not possible to differentiate observations based on two dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a64e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO plot it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a3d97a",
   "metadata": {},
   "source": [
    "Plot the graph of cumulative explained variance vs number of components. You might also want to make an additional plot for the first N components. How many components should we use to describe the data? Motivate your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb84962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = sum(eig_vals)\n",
    "var_exp = [(i / tot)*100 for i in sorted(eig_vals, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1edec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(range(4), var_exp, alpha=0.5, align='center',\n",
    "            label='individual explained variance')\n",
    "    plt.step(range(4), cum_var_exp, where='mid',\n",
    "             label='cumulative explained variance')\n",
    "    plt.ylabel('Explained variance')\n",
    "    plt.xlabel('Principal components')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe68607e",
   "metadata": {},
   "source": [
    "### 2.2.3 Visualizing the data in 3 dimensions (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401935bb",
   "metadata": {},
   "source": [
    "Reduce the dimensionality of the dataset to 3. Using Tensorboard visualize the resultant data in 3 dimensions. You should get the result similar to the [Embedding Projector](https://projector.tensorflow.org/) project (actually, they use the same Tensorboard package, so the result might be even exactly the same). You can use differently colored points instead of the digit pictures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfb66e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82efdaf9",
   "metadata": {},
   "source": [
    "Analyze the resultant plot.  \n",
    "Is 3 dimensions considerably better than 2?  \n",
    "Which digits stand out in 3D and which digits are difficult to differentiate in 3 dimensions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b623ec85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
