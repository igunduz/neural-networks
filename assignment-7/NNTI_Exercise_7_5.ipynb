{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f3e234d",
   "metadata": {},
   "source": [
    "Name:   Anh Tuan Tran\n",
    "Matrikelnummer:  7015463\n",
    "Email:   antr00001@stud.uni-saarland.de\n",
    "   \n",
    "Name:   Deborah Dormah Kanubala\n",
    "Matrikelnummer:   7025906\n",
    "Email:  dkanubala@aimsammi.org\n",
    "\n",
    "Name:    Irem Begüm Gündüz\n",
    "Matrikelnummer:     7026821\n",
    "Email: irgu00001@stud.uni-saarland.de"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada51e96",
   "metadata": {},
   "source": [
    "#### Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bb034177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import necessary libraries\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121bd9f9",
   "metadata": {},
   "source": [
    "# 7.5 Build your own regularized NN\n",
    "\n",
    "In this exercise you get to use your previously built networks, but this time you need to add regularization in the form of dropout and $L_2$-regularization.\n",
    "\n",
    "Each layer has the option of using dropout. Your code needs to allow for this flexibility.\n",
    "\n",
    "Additionally, adding $L_2$-regularization should also be optional upon creation.\n",
    "\n",
    "**NOTE**: You are allowed to use built-in functions from pytorch to incorporate this functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f66f378",
   "metadata": {},
   "source": [
    "### 7.5.1 Implement a regularized model (1 point)\n",
    "\n",
    "Implement your own model (using `torch`) using the skeleton code provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3114d8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \"\"\"\n",
    "    Implement a model that incorporates dropout and L2 regularization\n",
    "    depending on arguments passed.\n",
    "    \n",
    "    Args:\n",
    "    input_dim: dimensionality of the inputs\n",
    "    hidden_dim: how many units each hidden layer will have\n",
    "    out_dim: how many output units\n",
    "    num_layers: how many hidden layers to create/use\n",
    "    dropout: a list of booleans specifying which hidden layers will have dropout\n",
    "    dropout_p: the probability used for the `Dropout` layers\n",
    "    l2_reg: a boolean value that indicates whether L2 regularization should be used\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 input_dim: int,\n",
    "                 hidden_dim: int,\n",
    "                 out_dim: int,\n",
    "                 num_layers: int,\n",
    "                 dropout: list,\n",
    "                 dropout_p: float,\n",
    "                 l2_reg: bool):\n",
    "        super(Model, self).__init__()\n",
    "        # Using l2 regularization or not (will be used when calculating loss)\n",
    "        self.l2_reg = l2_reg\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        # hidden layers\n",
    "        layers = []\n",
    "        for i in range (num_layers):\n",
    "            if i == 0:\n",
    "                _in_dim = input_dim\n",
    "            else:\n",
    "                _in_dim = hidden_dim\n",
    "            _out_dim = hidden_dim\n",
    "            layers.append(nn.Linear(_in_dim, _out_dim, bias=True))\n",
    "            layers.append(nn.ReLU())\n",
    "            if dropout[i]:\n",
    "                layers.append(nn.Dropout(p=dropout_p))\n",
    "        \n",
    "        # output layer\n",
    "        layers.append(nn.Linear(hidden_dim, out_dim))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward (self, inp):\n",
    "        inp = inp.view (-1, self.input_dim)\n",
    "        return self.layers(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33aeb6d0",
   "metadata": {},
   "source": [
    "### 7.5.2 Experiment with your model (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69876914",
   "metadata": {},
   "source": [
    "Use the MNIST dataset and evaluation code from the previous assignment to run some experiments. Run the following experiments:\n",
    "\n",
    "1. Shallow network (not more than 1 hidden layer)\n",
    "1. Shallow regularized network\n",
    "1. Deep network (at least 3 hidden layers)\n",
    "1. Deep regularized network\n",
    "\n",
    "Report Accuracy and $F_1$ metrics for your experiments and discuss your results. What did you expect to see and what did you end up seeing.\n",
    "\n",
    "**NOTE**: You can choose how you use regularization. Ideally you would experiment with various parameters for this regularization, the 4 listed variants are merely what you must cover as a minimum. Report results for all your experiments concisely in a table.\n",
    "\n",
    "**NOTE 2**: Make sure to report your metrics on the training and evaluation/heldout sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11d423b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2.2%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31.0%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "79.2%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102.8%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "112.7%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "# DO NOT CHANGE THE CODE IN THIS CELL EXCEPT FOR THE BATCH SIZE IF NECESSARY\n",
    "transform_fn = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.7,), (0.7,)),])\n",
    "\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform_fn)\n",
    "train_dl = torch.utils.data.DataLoader(mnist_train, batch_size=32, shuffle=True)\n",
    "\n",
    "mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transform_fn)\n",
    "test_dl = torch.utils.data.DataLoader(mnist_test, batch_size=32, shuffle=False)\n",
    "\n",
    "# Use the above data for your experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "381ae0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(data, model, loss_fn, l2_weight=1e-2, num_epoch=4, learning_rate=1e-2):  \n",
    "    if model.l2_reg:\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=l2_weight)\n",
    "    else:\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model.train ()\n",
    "    losses = []\n",
    "    for i_epoch in range (num_epoch):\n",
    "        epoch_losses = []\n",
    "        for batch in  iter(data):\n",
    "            x, y = batch\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x)\n",
    "            loss = loss_fn (y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_losses.append (loss.detach ().numpy ())\n",
    "#         if i_epoch % 100 == 0:\n",
    "        print (\"epoch:\", i_epoch, \"mean epoch loss:\", np.mean (epoch_losses))\n",
    "        losses.append (np.mean (epoch_losses))\n",
    "    return losses\n",
    "\n",
    "def evaluate_loop(data, model, loss_fn, set_name='Test'):\n",
    "    model.eval()\n",
    "    size = len(data)\n",
    "    test_loss, correct = 0, 0\n",
    "    i = 0\n",
    "    \n",
    "    TP, FP, FN = 0, 0, 0\n",
    "    \n",
    "    preds = []\n",
    "    gts = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iter(data):\n",
    "            \n",
    "            X, y = batch\n",
    "            i += int(y.size(0))\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).sum().item()\n",
    "            pred = pred.argmax(1).numpy().tolist ()\n",
    "            preds.extend (pred)\n",
    "            gts.extend (y.numpy ().tolist ())\n",
    "            \n",
    "    test_loss /= i\n",
    "    correct /= i\n",
    "    f1_scores = f1_score (preds, gts, average='micro')\n",
    "    \n",
    "    print(set_name + f\" Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\")\n",
    "    print (set_name + \" f1 scores: \", f1_scores)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4dceb298",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 28 * 28\n",
    "output_dim = 10\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-2\n",
    "hidden_dim = 128\n",
    "l2_weight = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ffe95a",
   "metadata": {},
   "source": [
    "#### Shallow network (not use L2 regularization and dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "822ed3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 mean epoch loss: 0.5171073\n",
      "epoch: 1 mean epoch loss: 0.39869726\n",
      "epoch: 2 mean epoch loss: 0.36913988\n",
      "epoch: 3 mean epoch loss: 0.36770475\n",
      "epoch: 4 mean epoch loss: 0.35216275\n",
      "epoch: 5 mean epoch loss: 0.34529477\n",
      "epoch: 6 mean epoch loss: 0.3470298\n",
      "epoch: 7 mean epoch loss: 0.33369783\n",
      "epoch: 8 mean epoch loss: 0.32655314\n",
      "epoch: 9 mean epoch loss: 0.33219647\n",
      "TestAccuracy: 91.0%, Avg loss: 0.010272\n",
      "Test f1 scores:  0.9098\n",
      "TrainAccuracy: 91.0%, Avg loss: 0.009636\n",
      "Train f1 scores:  0.9100666666666667\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed (10)\n",
    "\n",
    "num_layers = 1\n",
    "dropout = [False] * num_layers\n",
    "dropout_p = 0.2\n",
    "l2_reg = False\n",
    "\n",
    "model = Model(input_dim, hidden_dim, output_dim, num_layers, dropout, dropout_p, l2_reg)\n",
    "train_loop(train_dl, model, loss_fn, num_epoch=10)\n",
    "evaluate_loop(test_dl, model, loss_fn)\n",
    "evaluate_loop(train_dl, model, loss_fn, \"Train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e92a4a",
   "metadata": {},
   "source": [
    "#### Shallow network (use L2 regularization and dropout for all layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "43f60ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 mean epoch loss: 1.1116096\n",
      "epoch: 1 mean epoch loss: 1.2757297\n",
      "epoch: 2 mean epoch loss: 1.2971585\n",
      "epoch: 3 mean epoch loss: 1.2848763\n",
      "epoch: 4 mean epoch loss: 1.2920935\n",
      "epoch: 5 mean epoch loss: 1.3280604\n",
      "epoch: 6 mean epoch loss: 1.4148575\n",
      "epoch: 7 mean epoch loss: 1.3138914\n",
      "epoch: 8 mean epoch loss: 1.4355352\n",
      "epoch: 9 mean epoch loss: 1.3010944\n",
      "TestAccuracy: 77.8%, Avg loss: 0.030824\n",
      "Test f1 scores:  0.7781\n",
      "TrainAccuracy: 76.7%, Avg loss: 0.031459\n",
      "Train f1 scores:  0.7670166666666667\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed (10)\n",
    "\n",
    "num_layers = 1\n",
    "dropout = [True] * num_layers\n",
    "dropout_p = 0.2\n",
    "l2_reg = True\n",
    "\n",
    "model = Model(input_dim, hidden_dim, output_dim, num_layers, dropout, dropout_p, l2_reg)\n",
    "train_loop(train_dl, model, loss_fn, num_epoch=10)\n",
    "evaluate_loop(test_dl, model, loss_fn)\n",
    "evaluate_loop(train_dl, model, loss_fn, \"Train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1f47e6",
   "metadata": {},
   "source": [
    "#### Deep network (3 hidden layers, not use L2 regularization and dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ee5d1fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 mean epoch loss: 0.42152494\n",
      "epoch: 1 mean epoch loss: 0.2077022\n",
      "epoch: 2 mean epoch loss: 0.16131927\n",
      "epoch: 3 mean epoch loss: 0.13877788\n",
      "epoch: 4 mean epoch loss: 0.12274186\n",
      "epoch: 5 mean epoch loss: 0.10574757\n",
      "epoch: 6 mean epoch loss: 0.096944235\n",
      "epoch: 7 mean epoch loss: 0.08912283\n",
      "epoch: 8 mean epoch loss: 0.0848133\n",
      "epoch: 9 mean epoch loss: 0.07850643\n",
      "Test Accuracy: 96.9%, Avg loss: 0.003288\n",
      "Test f1 scores:  0.9693\n",
      "Train Accuracy: 98.2%, Avg loss: 0.001741\n",
      "Train f1 scores:  0.9815166666666667\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed (10)\n",
    "\n",
    "num_layers = 3\n",
    "dropout = [False] * num_layers\n",
    "dropout_p = 0.2\n",
    "l2_reg = False\n",
    "\n",
    "model = Model(input_dim, hidden_dim, output_dim, num_layers, dropout, dropout_p, l2_reg)\n",
    "train_loop(train_dl, model, loss_fn, num_epoch=10, learning_rate=1e-3)\n",
    "evaluate_loop(test_dl, model, loss_fn)\n",
    "evaluate_loop(train_dl, model, loss_fn, \"Train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a75c821",
   "metadata": {},
   "source": [
    "#### Deep network (3 hidden layers, use L2 regularization and dropout for all layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fbc2e278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 mean epoch loss: 0.6207891\n",
      "epoch: 1 mean epoch loss: 0.44457653\n",
      "epoch: 2 mean epoch loss: 0.42135078\n",
      "epoch: 3 mean epoch loss: 0.41527197\n",
      "epoch: 4 mean epoch loss: 0.4058945\n",
      "epoch: 5 mean epoch loss: 0.40442845\n",
      "epoch: 6 mean epoch loss: 0.40433857\n",
      "epoch: 7 mean epoch loss: 0.40379792\n",
      "epoch: 8 mean epoch loss: 0.40211317\n",
      "epoch: 9 mean epoch loss: 0.4072769\n",
      "Test Accuracy: 92.7%, Avg loss: 0.007682\n",
      "Test f1 scores:  0.9273\n",
      "Train Accuracy: 92.7%, Avg loss: 0.007810\n",
      "Train f1 scores:  0.9268166666666666\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed (10)\n",
    "\n",
    "num_layers = 3\n",
    "dropout = [True] * num_layers\n",
    "dropout_p = 0.2\n",
    "l2_reg = True\n",
    "\n",
    "model = Model(input_dim, hidden_dim, output_dim, num_layers, dropout, dropout_p, l2_reg)\n",
    "train_loop(train_dl, model, loss_fn, num_epoch=10, learning_rate=1e-3)\n",
    "evaluate_loop(test_dl, model, loss_fn)\n",
    "evaluate_loop(train_dl, model, loss_fn, \"Train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407cc55f",
   "metadata": {},
   "source": [
    "#### Deep network (5 hidden layers, not use L2 regularization and dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c5f6ce91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 mean epoch loss: 0.48359734\n",
      "epoch: 1 mean epoch loss: 0.23092112\n",
      "epoch: 2 mean epoch loss: 0.17692493\n",
      "epoch: 3 mean epoch loss: 0.1572411\n",
      "epoch: 4 mean epoch loss: 0.13244267\n",
      "epoch: 5 mean epoch loss: 0.12145918\n",
      "epoch: 6 mean epoch loss: 0.11138751\n",
      "epoch: 7 mean epoch loss: 0.096630335\n",
      "epoch: 8 mean epoch loss: 0.09768703\n",
      "epoch: 9 mean epoch loss: 0.0872717\n",
      "Test Accuracy: 96.2%, Avg loss: 0.004154\n",
      "Test f1 scores:  0.9617\n",
      "Train Accuracy: 97.3%, Avg loss: 0.002636\n",
      "Train f1 scores:  0.9727333333333333\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed (10)\n",
    "\n",
    "num_layers = 5\n",
    "dropout = [False] * num_layers\n",
    "dropout_p = 0.2\n",
    "l2_reg = False\n",
    "\n",
    "model = Model(input_dim, hidden_dim, output_dim, num_layers, dropout, dropout_p, l2_reg)\n",
    "train_loop(train_dl, model, loss_fn, num_epoch=10, learning_rate=1e-3)\n",
    "evaluate_loop(test_dl, model, loss_fn)\n",
    "evaluate_loop(train_dl, model, loss_fn, \"Train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c5c209",
   "metadata": {},
   "source": [
    "#### Deep network (5 hidden layers, use dropout for all layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1a90f06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 mean epoch loss: 0.7416826\n",
      "epoch: 1 mean epoch loss: 0.43363568\n",
      "epoch: 2 mean epoch loss: 0.3850245\n",
      "epoch: 3 mean epoch loss: 0.361695\n",
      "epoch: 4 mean epoch loss: 0.33900133\n",
      "epoch: 5 mean epoch loss: 0.31971908\n",
      "epoch: 6 mean epoch loss: 0.3133735\n",
      "epoch: 7 mean epoch loss: 0.30384713\n",
      "epoch: 8 mean epoch loss: 0.29254916\n",
      "epoch: 9 mean epoch loss: 0.29017526\n",
      "Test Accuracy: 95.0%, Avg loss: 0.005383\n",
      "Test f1 scores:  0.9501\n",
      "Train Accuracy: 95.2%, Avg loss: 0.005090\n",
      "Train f1 scores:  0.9520166666666665\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed (10)\n",
    "\n",
    "num_layers = 5\n",
    "dropout = [True] * num_layers\n",
    "dropout_p = 0.2\n",
    "l2_reg = False\n",
    "\n",
    "model = Model(input_dim, hidden_dim, output_dim, num_layers, dropout, dropout_p, l2_reg)\n",
    "train_loop(train_dl, model, loss_fn, num_epoch=10, learning_rate=1e-3)\n",
    "evaluate_loop(test_dl, model, loss_fn)\n",
    "evaluate_loop(train_dl, model, loss_fn, \"Train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dd6209",
   "metadata": {},
   "source": [
    "#### Deep network (5 hidden layers, use dropout for first hidden layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "023753e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 mean epoch loss: 0.62281764\n",
      "epoch: 1 mean epoch loss: 0.33964366\n",
      "epoch: 2 mean epoch loss: 0.29113665\n",
      "epoch: 3 mean epoch loss: 0.26444286\n",
      "epoch: 4 mean epoch loss: 0.24793516\n",
      "epoch: 5 mean epoch loss: 0.23228389\n",
      "epoch: 6 mean epoch loss: 0.22169606\n",
      "epoch: 7 mean epoch loss: 0.20569672\n",
      "epoch: 8 mean epoch loss: 0.20357373\n",
      "epoch: 9 mean epoch loss: 0.19426337\n",
      "Test Accuracy: 95.8%, Avg loss: 0.004240\n",
      "Test f1 scores:  0.9576\n",
      "Train Accuracy: 96.3%, Avg loss: 0.003743\n",
      "Train f1 scores:  0.9627666666666667\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed (10)\n",
    "\n",
    "num_layers = 5\n",
    "dropout = [False] * num_layers\n",
    "dropout[0] = True\n",
    "dropout_p = 0.2\n",
    "l2_reg = False\n",
    "\n",
    "model = Model(input_dim, hidden_dim, output_dim, num_layers, dropout, dropout_p, l2_reg)\n",
    "train_loop(train_dl, model, loss_fn, num_epoch=10, learning_rate=1e-3)\n",
    "evaluate_loop(test_dl, model, loss_fn)\n",
    "evaluate_loop(train_dl, model, loss_fn, \"Train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a528187a",
   "metadata": {},
   "source": [
    "#### Deep network (5 hidden layers, not use L2 regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "647bed48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 mean epoch loss: 1.1919228\n",
      "epoch: 1 mean epoch loss: 0.53703046\n",
      "epoch: 2 mean epoch loss: 0.45945904\n",
      "epoch: 3 mean epoch loss: 0.42421094\n",
      "epoch: 4 mean epoch loss: 0.4101319\n",
      "epoch: 5 mean epoch loss: 0.3975013\n",
      "epoch: 6 mean epoch loss: 0.39467883\n",
      "epoch: 7 mean epoch loss: 0.3911738\n",
      "epoch: 8 mean epoch loss: 0.38654754\n",
      "epoch: 9 mean epoch loss: 0.3843605\n",
      "Test Accuracy: 89.6%, Avg loss: 0.011126\n",
      "Test f1 scores:  0.8957\n",
      "Train Accuracy: 89.9%, Avg loss: 0.011001\n",
      "Train f1 scores:  0.89875\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed (10)\n",
    "\n",
    "num_layers = 5\n",
    "dropout = [False] * num_layers\n",
    "dropout_p = 0.2\n",
    "l2_reg = True\n",
    "\n",
    "model = Model(input_dim, hidden_dim, output_dim, num_layers, dropout, dropout_p, l2_reg)\n",
    "train_loop(train_dl, model, loss_fn, num_epoch=10, learning_rate=1e-3)\n",
    "evaluate_loop(test_dl, model, loss_fn)\n",
    "evaluate_loop(train_dl, model, loss_fn, \"Train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1b43f4",
   "metadata": {},
   "source": [
    "### 7.5.3 Get the best model! (1 + 1 point (bonus))\n",
    "\n",
    "* Present your model during a tutorial session. Justify your decisions when designing your model/solution.\n",
    "* If you achieve one of the top N results, you get yet another extra point!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8529ddb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30227e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c4ebae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
